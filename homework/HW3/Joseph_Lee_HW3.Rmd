---
title: "STAT 385 Fall 2019 - Homework Assignment 03"
date: "Due by 12:00 PM 10/13/2019"
output: html_document
---


## The Homework Problems

Below you will find problems for you to complete as an individual. It is fine to discuss the homework problems with classmates, but cheating is prohibited and will be harshly penalized if detected.

### 1. Create a custom volume measurement function that will convert the following units of volume:

a. 13 imperial (liquid) cups to cubic inches.
```{r}
CupToInch = function(x) {
  x*14.4375
}
CupToInch(13)
```

b. 2.5 US customary (liquid) gallons to fluid ounces.
```{r}
GalToOz = function(x) {
  128*x
}
GalToOz(2.5)
```

c. 3 US customary (dry) teaspoons to milliliters.
```{r}
TspTomL = function(x) {
  4.92892*x
}
TspTomL(3)
```

d. 75 (dry) liters to imperial quarts.
```{r}
LtoQz = function(x) {
  1.05669*x
}
LtoQz(75)
```

### 2. Do the following:

a. create a 25 $\times$ 25 matrix with autoregressive structure with $p = 9/10$, every element in the matrix should be equal to $(9/10)^{|i-j|}$ where `i` is the row index and `j` is the column index.  Report the row and column sums of this matrix.
```{r}
mat = matrix(rep((9/10),25^2),nrow=25,ncol=25)
for(i in 1:25) {
  for(j in 1:25) {
    mat[i,j] = mat[i,j]^abs(i-j)
  }
}
apply(mat,1,sum)
apply(mat,2,sum)
```

b. run the commands:

```{r}
set.seed(13)
x <- c(10, 10) 
n <- 2
```

Create a while loop which concatenates a new mean-zero normal random variables that have $\sigma = 2$ to the existing vector `x` at every iteration.  Have this loop terminate when the standard error (estimated standard deviation of `x` divided by $\sqrt{n}$) is lower than 1/10.  Report $n$.  
```{r}
while(TRUE){
  x = append(x,rnorm(1,sd = 2))
  n = n+1
  if (sd(x)/sqrt(n)<1/10) {
    break
  }
}
n
```

c. repeat part **b** and report $n$ after running the commands:    

```{r}
set.seed(13)
x <- rnorm(0, sd = 2)
n <- 1
```

```{r}
while(TRUE){
  x = append(x,rnorm(1,sd = 2))
  n = n+1
  if (n>2){
    if (sd(x)/sqrt(n) < 1/10){
      break
    }
  }
}
n
```

d. The sample size required to get a standard error lower than 1/10 was smaller in part **c** than it was in part **b**.  We would expect for this to be the case before we ran any code.  Why?

In part b x was defined as a vector with 2 elements of value 10, while in part c x was defined as an empty random variable, so standard error becomes smaller quicker.

### 3. Do the following (Efron's bootstrap):

a. load in the dataset [dataHW3.csv](https://uofi.box.com/shared/static/mwntzgp2rvyewf292k6i62pykjz1onnw.csv)
```{r}
data = read.csv("dataHW3.csv")
```

b. call the first column of this dataset x. Compute the statistic `(mean(x) - 10)/se(x)` where `se` is shorthand for standard error (see the previous problem for the definition of standard error).  
```{r}
x = data[,1]
se = function(x) sd(x)/sqrt(length(x))
(mean(x) - 10)/se(x)
```

c. now resample the elements of x with replacement 10000 times, and compute and store the statistic (mean(x') - mean(x))/se(x') at each iteration where x' corresponds to the resample of the elements of x. Call the vector which contains these reasampled statistics `resamples'.  Use an apply function for this part.  
```{r}
B = 1e4
resamples = rep(0,B)
y = replicate(B,sample(x, replace = TRUE))
resamples = apply(y,2, function(y)(mean(y) - mean(x)) / se(y))
```

d.  run the command `hist(resamples, breaks = 20)' to make a histogram, include this histogram in your assignment.
```{r}
hist(resamples, breaks = 20)
```

e. repeat parts **b** through **d** with respect to the second column of dataHW3.csv.  Would you say that the test statistic calculated from each column has the same distribution?
```{r}
x = data[,2]
B = 1e4
resamples2 = rep(0,B)
y = replicate(B,sample(x, replace = TRUE))
resamples2 = apply(y,2, function(y)(mean(y) - mean(x)) / se(y))
hist(resamples2,breaks = 20)
```

No, definitely not. The first column is normally distributed, but the distribution of the second column is very much left-skewed.

### 4. Do the following:

a. make sure you have the dataset [WPP2010.csv](https://uofi.box.com/shared/static/vielwghs3qtdf2p25nejeiaq6ce9nonf.csv) (your file location may need to change) and then run the commands: 

```{r}
# load in UN dataset and remove irrelevant variables
options(warn=-1)
WPP2010 <- read.csv("WPP2010.csv", header = TRUE)
colnames(WPP2010)[3] <- c("region")
colnames(WPP2010)[6] <- c("year")
colnames(WPP2010)[7:17] <- paste("age", 0:10 * 5, sep = "")
WPP2010 <- WPP2010[, c(3, 6, 11, 12)]

# restrict attention to countries of interest
countries <- c("Canada", "Mexico", "United States of America")

# obtain population data for all countries for all years
dataset <- WPP2010[WPP2010[, 1] %in% countries, ]
dataset[, 3] <- as.numeric(levels(dataset[, 3]))[dataset[, 3]]
dataset[, 4] <- as.numeric(levels(dataset[, 4]))[dataset[, 4]]
dataset[, 3:4] <- dataset[, 3:4] / 1000

# get population dataset for this analysis corresponding to the 
# Census years 
dataset.years <- dataset[dataset[, 2] %in% 
  c("1960", "1970", "1980", "1990", "2000", "2010"), ]
#Change Census years into factor variables
dataset.years[, 2] <- factor(dataset.years[, 2])
#Split the data into groups by year
dataset.years.list <- split(dataset.years, f = as.factor(dataset.years[, 2]))
#list of sums of the different age groups for each year
pops <- unlist(lapply(dataset.years.list, function(x) sum(x[, 3:4])))
```

b. The code in part **a** is partially commented.  Add comments to all remaining lines of code to make the script clear.

c. Determine the proportion of mainland North American males aged 20-29 that lived in 1970 or before.
```{r}
(sum(dataset.years.list$`1960`[3,3:4])+sum(dataset.years.list$`1970`[3,3:4]))/sum(pops)
```



### 5. With the tidyverse package and its functions, do the following with the [CCSO Bookings Data](https://uofi.box.com/shared/static/9elozjsg99bgcb7gb546wlfr3r2gc9b7.csv):

a. show only the 2012 bookings for people ages 17-23 years old not residing in Illinois and show the data dimension
```{r}
library(tidyverse)
ccso = read.csv("CCSO Data.csv")
ccso$BOOKING.DATE = as.Date(ccso$BOOKING.DATE, format = "%m/%d/%Y")
data = filter(ccso, BOOKING.DATE >= as.Date("2012-1-1") & BOOKING.DATE <= as.Date("2012-12-31"), 17 < Age.at.Arrest & Age.at.Arrest < 23, STATE != "ILLINOIS")
dim(data)
```

b. show only the bookings for people who have employment status as "student" booked after the year 2012 residing in Danville and show the data dimension
```{r}
data = filter(ccso, EMPLOYMENT.STATUS == "Student", BOOKING.DATE > as.Date("2012-12-31"), CITY == "DANVILLE")
dim(data)
```

c. show only the bookings for Asian people residing in the cities of Champaign or Urbana and show the data dimension
```{r}
data = filter(ccso, RACE == "Asian/Pacific Islander", CITY == "CHAMPAIGN" | CITY == "URBANA")
dim(data)
```

d. repeat parts a-c using only pipe operators
```{r}
data = ccso %>% filter(BOOKING.DATE >= as.Date("2012-1-1") & BOOKING.DATE <= as.Date("2012-12-31"), 17 < Age.at.Arrest & Age.at.Arrest < 23, STATE != "ILLINOIS")
dim(data)
```

```{r}
data = ccso %>% filter(EMPLOYMENT.STATUS == "Student", BOOKING.DATE > as.Date("2012-12-31"), CITY == "DANVILLE")
dim(data)
```

```{r}
data = ccso %>% filter(RACE == "Asian/Pacific Islander", CITY == "CHAMPAIGN" | CITY == "URBANA")
dim(data)
```

## Select in-class tasks

Completion of select in-class tasks will be worth 1 point and will be graded largely by completion. Obvious errors and incomplete work will recieve deductions. Problems 3-5 are directly copied from your notes. Problems 1-2 are copied from the notes with minor alterations. In these problems I ask that you display the first 5 rows of the dataset instead of the entire dataset.

1. Load in the CCSO dataset, discover 3 factor (or categorical) variables and 3 numeric variables. Show the first 5 rows of this dataset with only those 6 variables. 
```{r}
ccso = read.csv("CCSO Data.csv")
str(ccso)
ccso[1:5, c("CUSTODY.CLASS", "CITY", "RACE", "Age.at.Arrest", "JACKET.NUMBER", "BOOKING.NUMBER")]
```

2. Rename one of the factor variables to a name that is either easier to understand than the original variable name. Show the first 5 rows of the dataset with all variables such that the variable with the new name is the first column in the dataset.
```{r}
names(ccso)[which(names(ccso)== "CUSTODY.CLASS")] = "REASON.CUSTODY"
ccso[1:5, c("REASON.CUSTODY", "CITY", "RACE", "Age.at.Arrest", "JACKET.NUMBER", "BOOKING.NUMBER")]
```

3. Write 3 separate loops: a for loop, while loop, and repeat loop that give the same result. The result should be the cumulative sum of Days in jail among Black people whose Arrest Ages 18-24 with Student as Employment status within the CCSO Bookings Data.
```{r}
sum = 0
subdata = filter(ccso,RACE == "Black" , Age.at.Arrest > 18 & Age.at.Arrest < 24,EMPLOYMENT.STATUS == "Student")
subdata$Days.in.Jail = as.numeric(subdata$Days.in.Jail)

for (i in 1:length(subdata$Days.in.Jail)) {
  sum = sum + subdata$Days.in.Jail[i]
}
sum
sum2 = 0
i = 1
while(i <= length(subdata$Days.in.Jail)) {
  sum2 = sum2 + subdata$Days.in.Jail[i]
  i = i + 1
}
sum2

sum3 = 0
i = 1
repeat {
  sum2 = sum2 + subdata$Days.in.Jail[i]
  i = i + 1
  if (i >length(subdata$Days.in.Jail)){
    break;
  }
}
```

4. Here are some images of R code. Read the code, debug it if necessary, and judge it on its efficiency and correctness. Decide on which set of code is better and improve the better one.

a.

![](https://uofi.box.com/shared/static/2x1h70d5skqpxwke8ftw7xx1rwu41397.jpg)

Both do result in the same matrix, but the second set is much cleaner and makes more sense.

b.

![](https://uofi.box.com/shared/static/xn2lop472prp18720uevoj4dpyfmtxwq.jpg)

The first set of code makes three separate lists of the numbers 1-10, a diagonal matrix, and the letters of the alphabet. The second set just combines them into one large vector. The first code is better in presenting the data as a list of different sets instead of one lump of data.

c.

![](https://uofi.box.com/shared/static/zsr6nmyayso7emjkmk6cfwaxs75wujpj.jpg)

Not sure what the first set of code is trying to achieve besides sorting the petal lengths, but the second set of code seems to be solid in finding the sum of petal lengths between 0 and 3.

5. Using the vector y below
```{r nt5}
set.seed(385)
y <- rnorm(100)
```

  a. Use the which.min and which.max functions to dispay the index corresponding to the minimum and maximum elements of `y`.
```{r}
which.min(y)
which.max(y)
```
  
  b. Do the which.min and which.max functions work? (try: max(y) == y[which.max(y)]).
```{r}
max(y) == y[which.max(y)]
min(y) == y[which.min(y)]
```
  Yes, they work
  
  c. Use the which function and the length function to report the proportion of the elements of `y` that are greater than 0.
```{r}
length(which(y>0))/length(y)
```

  d. Discuss why the proportion in **part c** is close to 0.5. Hint: What is the mean of the normal distribution that generated the elements in `y`?
  
y generates 100 random variables from the normal distribution, so the data stored in y is normally distributed. So around 0.5 of the elements in y are greater than 0 since the normal distribution is centered at 0.
  
  e. Create a factor variable with 50 values of `A` and 50 values of `B`, and name this factor variable `trt`. 
```{r}
trt = factor(c(rep('A',50),rep('B',50)))
trt
```
  
  f. Create a data frame consisting of `x` and `trt`.
```{r}
x = 1:100

df = data.frame(x, trt)
```
  
  